{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM8pN4e0V3c9KTC+dWaM7zR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JSJeong-me/GPT-Web/blob/main/122-function_call_api.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### https://cookbook.openai.com/examples/how_to_call_functions_with_chat_models\n"
      ],
      "metadata": {
        "id": "es8jDdU_JJJ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai==0.28\n",
        "!pip install python-dotenv"
      ],
      "metadata": {
        "id": "LOD8ANuqgeo1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!echo \"OPENAI_API_KEY=sk-\" >> .env"
      ],
      "metadata": {
        "id": "u3nQc-cyglgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!source /content/.env"
      ],
      "metadata": {
        "id": "JwKBV8lzgqnW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load environment variables from .env file\n",
        "load_dotenv()\n",
        "# Access the API key using the variable name defined in the .env file\n",
        "api_key = os.getenv(\"OPENAI_API_KEY\")"
      ],
      "metadata": {
        "id": "8fl4M1lhgsso"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f6fAcxvKGXFV"
      },
      "outputs": [],
      "source": [
        "!pip install scipy\n",
        "!pip install tenacity\n",
        "!pip install tiktoken\n",
        "!pip install termcolor\n",
        "!pip install openai\n",
        "!pip install requests"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import openai\n",
        "import requests\n",
        "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
        "from termcolor import colored\n",
        "\n",
        "GPT_MODEL = \"gpt-3.5-turbo-0613\""
      ],
      "metadata": {
        "id": "Jtyyg_UuGe1Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the OpenAI API client\n",
        "openai.api_key = \"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\""
      ],
      "metadata": {
        "id": "r6Uev4x0HbCT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@retry(wait=wait_random_exponential(multiplier=1, max=40), stop=stop_after_attempt(3))\n",
        "def chat_completion_request(messages, functions=None, function_call=None, model=GPT_MODEL):\n",
        "    headers = {\n",
        "        \"Content-Type\": \"application/json\",\n",
        "        \"Authorization\": \"Bearer \" + openai.api_key,\n",
        "    }\n",
        "    json_data = {\"model\": model, \"messages\": messages}\n",
        "    if functions is not None:\n",
        "        json_data.update({\"functions\": functions})\n",
        "    if function_call is not None:\n",
        "        json_data.update({\"function_call\": function_call})\n",
        "    try:\n",
        "        response = requests.post(\n",
        "            \"https://api.openai.com/v1/chat/completions\",\n",
        "            headers=headers,\n",
        "            json=json_data,\n",
        "        )\n",
        "        return response\n",
        "    except Exception as e:\n",
        "        print(\"Unable to generate ChatCompletion response\")\n",
        "        print(f\"Exception: {e}\")\n",
        "        return e\n"
      ],
      "metadata": {
        "id": "U5NdHUKGGq3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pretty_print_conversation(messages):\n",
        "    role_to_color = {\n",
        "        \"system\": \"red\",\n",
        "        \"user\": \"green\",\n",
        "        \"assistant\": \"blue\",\n",
        "        \"function\": \"magenta\",\n",
        "    }\n",
        "\n",
        "    for message in messages:\n",
        "        if message[\"role\"] == \"system\":\n",
        "            print(colored(f\"system: {message['content']}\\n\", role_to_color[message[\"role\"]]))\n",
        "        elif message[\"role\"] == \"user\":\n",
        "            print(colored(f\"user: {message['content']}\\n\", role_to_color[message[\"role\"]]))\n",
        "        elif message[\"role\"] == \"assistant\" and message.get(\"function_call\"):\n",
        "            print(colored(f\"assistant: {message['function_call']}\\n\", role_to_color[message[\"role\"]]))\n",
        "        elif message[\"role\"] == \"assistant\" and not message.get(\"function_call\"):\n",
        "            print(colored(f\"assistant: {message['content']}\\n\", role_to_color[message[\"role\"]]))\n",
        "        elif message[\"role\"] == \"function\":\n",
        "            print(colored(f\"function ({message['name']}): {message['content']}\\n\", role_to_color[message[\"role\"]]))\n"
      ],
      "metadata": {
        "id": "BaqOWqbrGuQj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "functions = [\n",
        "    {\n",
        "        \"name\": \"get_current_weather\",\n",
        "        \"description\": \"Get the current weather\",\n",
        "        \"parameters\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"location\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
        "                },\n",
        "                \"format\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"enum\": [\"celsius\", \"fahrenheit\"],\n",
        "                    \"description\": \"The temperature unit to use. Infer this from the users location.\",\n",
        "                },\n",
        "            },\n",
        "            \"required\": [\"location\", \"format\"],\n",
        "        },\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"get_n_day_weather_forecast\",\n",
        "        \"description\": \"Get an N-day weather forecast\",\n",
        "        \"parameters\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"location\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
        "                },\n",
        "                \"format\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"enum\": [\"celsius\", \"fahrenheit\"],\n",
        "                    \"description\": \"The temperature unit to use. Infer this from the users location.\",\n",
        "                },\n",
        "                \"num_days\": {\n",
        "                    \"type\": \"integer\",\n",
        "                    \"description\": \"The number of days to forecast\",\n",
        "                }\n",
        "            },\n",
        "            \"required\": [\"location\", \"format\", \"num_days\"]\n",
        "        },\n",
        "    },\n",
        "]"
      ],
      "metadata": {
        "id": "XdFiRZsWGxKg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = []\n",
        "messages.append({\"role\": \"system\", \"content\": \"Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\"})\n",
        "messages.append({\"role\": \"user\", \"content\": \"What's the weather like today\"})\n",
        "chat_response = chat_completion_request(\n",
        "    messages, functions=functions\n",
        ")\n",
        "assistant_message = chat_response.json()[\"choices\"][0][\"message\"]\n",
        "messages.append(assistant_message)\n",
        "assistant_message\n"
      ],
      "metadata": {
        "id": "9h-xs352G9uj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_response.json()"
      ],
      "metadata": {
        "id": "tRiitlyih3qI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response_json = chat_response.json()\n",
        "if 'choices' in response_json:\n",
        "    assistant_message = response_json[\"choices\"][0][\"message\"]\n",
        "else:\n",
        "    # Handle the absence of 'choices' key\n",
        "    print(\"Key 'choices' not found in the response.\")\n"
      ],
      "metadata": {
        "id": "bFyX91mehsF7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages.append({\"role\": \"user\", \"content\": \"I'm in Glasgow, Scotland.\"})\n",
        "chat_response = chat_completion_request(\n",
        "    messages, functions=functions\n",
        ")\n",
        "assistant_message = chat_response.json()[\"choices\"][0][\"message\"]\n",
        "messages.append(assistant_message)\n",
        "assistant_message\n"
      ],
      "metadata": {
        "id": "9ZZP2rqNHz2_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = []\n",
        "messages.append({\"role\": \"system\", \"content\": \"Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\"})\n",
        "messages.append({\"role\": \"user\", \"content\": \"what is the weather going to be like in Glasgow, Scotland over the next x days\"})\n",
        "chat_response = chat_completion_request(\n",
        "    messages, functions=functions\n",
        ")\n",
        "assistant_message = chat_response.json()[\"choices\"][0][\"message\"]\n",
        "messages.append(assistant_message)\n",
        "assistant_message\n"
      ],
      "metadata": {
        "id": "ECl3AjLKIOBr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages.append({\"role\": \"user\", \"content\": \"5 days\"})\n",
        "chat_response = chat_completion_request(\n",
        "    messages, functions=functions\n",
        ")\n",
        "chat_response.json()[\"choices\"][0]\n"
      ],
      "metadata": {
        "id": "_3eSQw6jIcNV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# in this cell we force the model to use get_n_day_weather_forecast\n",
        "messages = []\n",
        "messages.append({\"role\": \"system\", \"content\": \"Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\"})\n",
        "messages.append({\"role\": \"user\", \"content\": \"Give me a weather report for Toronto, Canada.\"})\n",
        "chat_response = chat_completion_request(\n",
        "    messages, functions=functions, function_call={\"name\": \"get_n_day_weather_forecast\"}\n",
        ")\n",
        "chat_response.json()[\"choices\"][0][\"message\"]\n"
      ],
      "metadata": {
        "id": "OBDpGW0OImRw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# if we don't force the model to use get_n_day_weather_forecast it may not\n",
        "messages = []\n",
        "messages.append({\"role\": \"system\", \"content\": \"Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\"})\n",
        "messages.append({\"role\": \"user\", \"content\": \"Give me a weather report for Toronto, Canada.\"})\n",
        "chat_response = chat_completion_request(\n",
        "    messages, functions=functions\n",
        ")\n",
        "chat_response.json()[\"choices\"][0][\"message\"]\n"
      ],
      "metadata": {
        "id": "1qIz-oJuIsHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NnbiLLDfJO60"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4M_7uOYRJOrG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}