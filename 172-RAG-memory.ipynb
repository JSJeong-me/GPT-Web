{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOVbAO7WWGCEHdJ/bsvzezM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JSJeong-me/GPT-Web/blob/main/172-RAG-memory.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai==0.28\n",
        "!pip install python-dotenv\n",
        "!pip install langchain"
      ],
      "metadata": {
        "id": "mzuEwYNyXP-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!echo \"OPENAI_API_KEY=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\" >> .env\n",
        "!source /content/.env"
      ],
      "metadata": {
        "id": "sg5t2TznXRty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load environment variables from .env file\n",
        "load_dotenv()\n",
        "# Access the API key using the variable name defined in the .env file\n",
        "api_key = os.getenv(\"OPENAI_API_KEY\")"
      ],
      "metadata": {
        "id": "07i2n4scXYNJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "임의의 체인에 메모리를 추가하는 방법을 보여줍니다. 지금은 메모리 클래스를 사용할 수 있지만 수동으로 연결해야 합니다."
      ],
      "metadata": {
        "id": "puUvzzUoWyFz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "EQYqcqhVWw0N"
      },
      "outputs": [],
      "source": [
        "from operator import itemgetter\n",
        "\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
        "\n",
        "model = ChatOpenAI(temperature=0,               # 창의성 (0.0 ~ 2.0)\n",
        "                 max_tokens=2048,             # 최대 토큰수\n",
        "                #  model_name='ft:gpt-3.5-turbo-0613:shinkisa::8VomhV43') # Fine-tuning model - 세계 도시 기온 가져오기\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"You are a helpful chatbot\"),\n",
        "        MessagesPlaceholder(variable_name=\"history\"),\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt.messages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49dFwWqvB6oF",
        "outputId": "1390bf10-2998-49e8-d9ae-99f3f6a3002c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful chatbot')),\n",
              " MessagesPlaceholder(variable_name='history'),\n",
              " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}'))]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "memory = ConversationBufferMemory(return_messages=True)"
      ],
      "metadata": {
        "id": "GMr1p-o8W6eQ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "memory.load_memory_variables({})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HL8RBlmkW7Yn",
        "outputId": "c24248cc-3140-4964-ae58-f72d17877e55"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'history': []}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# {'history': []}"
      ],
      "metadata": {
        "id": "unAE_A04W9Ez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = (\n",
        "    RunnablePassthrough.assign(\n",
        "        history=RunnableLambda(memory.load_memory_variables) | itemgetter(\"history\")\n",
        "    )\n",
        "    | prompt\n",
        "    | model\n",
        ")"
      ],
      "metadata": {
        "id": "hTybG9D1W-mp"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain"
      ],
      "metadata": {
        "id": "WN3UudBECvsr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = {\"input\": \"What is the temperature in New York?\"}\n",
        "response = chain.invoke(inputs)\n",
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7ss3S1FXBds",
        "outputId": "be64acd4-7dab-4c7f-bfa1-cdd597695804"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='The current temperature in New York is 45°F (7°C).')"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = {\"input\": \"what is my name?\"}\n",
        "response = chain.invoke(inputs)\n",
        "response"
      ],
      "metadata": {
        "id": "cWTlkuZFEpbV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "memory.save_context(inputs, {\"output\": response.content})"
      ],
      "metadata": {
        "id": "bj4dHyjAXFPW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "memory.load_memory_variables({})"
      ],
      "metadata": {
        "id": "yufs4kuVXHO8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response"
      ],
      "metadata": {
        "id": "VhBL0OPbDGpM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}