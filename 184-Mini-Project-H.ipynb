{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPKuFg+M2WgrsHIA8V/jIKW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JSJeong-me/GPT-Web/blob/main/184-Mini-Project-H.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai langchain langchain_openai langchain_community langchain_chroma langchain_text_splitters"
      ],
      "metadata": {
        "id": "zUJjGBp-f-44"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import openai\n",
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "openai.api_key  = os.environ[\"OPENAI_API_KEY\"]"
      ],
      "metadata": {
        "id": "b8vd_4N8-Vx0"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Sample texts:\n",
        "\n",
        "texts 리스트에는 샘플 텍스트들이 포함되어 있습니다. 각 텍스트는 광대버섯(Amanita phalloides)에 대한 정보를 제공합니다.\n",
        "Custom text loader function:\n",
        "\n",
        "2. Custom text loader function:\n",
        "\n",
        "load_texts 함수는 주어진 텍스트 리스트를 받아서 Document 객체의 리스트로 변환합니다. Document 객체는 페이지 콘텐츠(텍스트 내용)와 메타데이터를 포함합니다.\n",
        "\n",
        "3.Load the documents:\n",
        "\n",
        "load_texts 함수를 사용하여 raw_documents 변수에 문서를 로드합니다.\n",
        "\n",
        "4. Initialize the text splitter and embeddings:\n",
        "\n",
        "CharacterTextSplitter 객체와 OpenAIEmbeddings 객체를 초기화합니다. CharacterTextSplitter는 텍스트를 일정 크기의 조각으로 분할하고, OpenAIEmbeddings는 텍스트 조각을 임베딩 벡터로 변환하는 역할을 합니다.\n",
        "\n",
        "5. Split the documents into chunks:\n",
        "\n",
        "각 문서를 100자 크기의 텍스트 조각으로 분할합니다. chunk_overlap이 0으로 설정되어 있으므로, 조각 사이에 중복이 없습니다.\n",
        "\n",
        "6. Embed each chunk:\n",
        "\n",
        "각 텍스트 조각을 임베딩합니다. 임베딩은 텍스트 조각을 벡터로 변환하여 기계 학습 모델이 이해할 수 있도록 합니다.\n",
        "\n",
        "7. Initialize the vector store with embedded chunks:\n",
        "\n",
        "Chroma 벡터 스토어를 초기화하고, 임베딩된 텍스트 조각들을 저장합니다. 이 벡터 스토어는 나중에 유사한 텍스트 검색을 수행하는 데 사용됩니다."
      ],
      "metadata": {
        "id": "Y3bc-JF-Jjxz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.docstore.document import Document  # Import the Document class"
      ],
      "metadata": {
        "id": "E8Twmg9fkqMF"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample texts\n",
        "texts = [\n",
        "    \"광대버섯(Amanita phalloides)은 크고 인상적인 후성(위) 자실체(담자과체)를 가지고 있습니다.\",\n",
        "    \"큰 자실체를 가진 버섯은 Amanita phalloides입니다. 일부 품종은 모두 흰색입니다.\",\n",
        "    \"A. phalloides, 일명 Death Cap은 알려진 모든 버섯 중에서 가장 독성이 강한 버섯 중 하나입니다.\",\n",
        "]"
      ],
      "metadata": {
        "id": "mdkDgmU--1BD"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom text loader function\n",
        "def load_texts(text_list):\n",
        "    documents = []\n",
        "    for text in text_list:\n",
        "        documents.append(Document(page_content=text, metadata={}))  # Create Document objects\n",
        "    return documents"
      ],
      "metadata": {
        "id": "gWd6viUN-3aa"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the documents\n",
        "raw_documents = load_texts(texts)"
      ],
      "metadata": {
        "id": "LzqG5XXt-9pT"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the text splitter and embeddings\n",
        "text_splitter = CharacterTextSplitter(chunk_size=100, chunk_overlap=0)\n",
        "embeddings = OpenAIEmbeddings()\n",
        "\n",
        "# Split the documents into chunks\n",
        "chunks = []\n",
        "for doc in raw_documents:\n",
        "    chunks.extend(text_splitter.split_text(doc.page_content))\n",
        "\n",
        "# Embed each chunk\n",
        "embedded_chunks = embeddings.embed_documents([chunk for chunk in chunks])  # Pass list of strings\n",
        "\n",
        "# Initialize the vector store with embedded chunks\n",
        "vector_store = Chroma.from_documents(\n",
        "    [Document(page_content=chunk, metadata={}) for chunk in chunks],\n",
        "    embeddings\n",
        ")"
      ],
      "metadata": {
        "id": "LiyQUa3t_CWU",
        "outputId": "96c49a71-9896-4ad1-d389-a0647483fdbc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-3387385245>:3: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
            "  embeddings = OpenAIEmbeddings()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def dynamic_search(question):\n",
        "#     try:\n",
        "#         k = int(input(\"원하는 검색 결과의 수를 입력하세요 (1-3): \"))\n",
        "#         if k < 1 or k > 3:\n",
        "#             raise ValueError(\"검색 결과의 수는 1에서 3 사이여야 합니다.\")\n",
        "#     except ValueError as e:\n",
        "#         print(f\"잘못된 입력입니다: {e}\")\n",
        "#         return []\n",
        "\n",
        "#     # Ensure vector_store is properly initialized and accessible\n",
        "#     return vector_store.similarity_search_with_score(query=question, k=k)"
      ],
      "metadata": {
        "id": "QL-JWoS3mrV6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 유사도 기반 검색 수행:\n",
        "\n",
        "retriever.get_relevant_documents(question)를 호출하여 질문에 대한 관련 문서를 검색합니다. 이 검색은 유사도 점수 임계값을 기준으로 필터링된 결과를 반환합니다."
      ],
      "metadata": {
        "id": "yVw_CaB8Lpg-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the retriever with a similarity score threshold\n",
        "retriever = vector_store.as_retriever(\n",
        "    search_type=\"similarity_score_threshold\", search_kwargs={\"score_threshold\": 0.75} # score_threshold\": 0.5, 0.8 0.9로 조절하여 정답 갯수를 확인\n",
        ")"
      ],
      "metadata": {
        "id": "KArLzVUqLaXD"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### score_threshold\":  0.5, 0.8 0.9 로 조절하여 정답 갯수를 확인"
      ],
      "metadata": {
        "id": "a3iM-bX7NOe2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dynamic_search_with_threshold(question):\n",
        "    \"\"\"\n",
        "\n",
        "    Args:\n",
        "      question:\n",
        "\n",
        "    Returns:\n",
        "\n",
        "    \"\"\"\n",
        "    try:\n",
        "        k = int(input(\"원하는 검색 결과의 수를 입력하세요 (1-3): \"))\n",
        "        if k < 1 or k > 3:\n",
        "            raise ValueError(\"검색 결과의 수는 1에서 3 사이여야 합니다.\")\n",
        "    except ValueError as e:\n",
        "        print(f\"잘못된 입력입니다: {e}\")\n",
        "        return []\n",
        "\n",
        "    # Perform the similarity search with the retriever\n",
        "    results = retriever.get_relevant_documents(question)\n",
        "\n",
        "    # Limit the results to the top k items\n",
        "    return results[:k]\n",
        "\n",
        "# Example usage\n",
        "question = \"고양이 다리가 몇개인가요?\"  # 광대버섯은 무엇입니까?\n",
        "results = dynamic_search_with_threshold(question)\n",
        "for result in results:\n",
        "    print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKwY6R4SLoZ_",
        "outputId": "dab82dc8-1cca-47c4-f30f-0b0bec03ed30"
      },
      "execution_count": 17,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "원하는 검색 결과의 수를 입력하세요 (1-3): 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_core.vectorstores.base:No relevant docs were retrieved using the relevance score threshold 0.75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1T0NnL8ONhgH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}