{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JSJeong-me/GPT-Web/blob/main/202-Llamaindex-Chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai==0.28"
      ],
      "metadata": {
        "id": "NKPoyHkuwTX4"
      },
      "id": "NKPoyHkuwTX4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show openai | grep Version"
      ],
      "metadata": {
        "id": "Wo_B38ZSwbtT"
      },
      "id": "Wo_B38ZSwbtT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama-index"
      ],
      "metadata": {
        "id": "zvZu_DGturyJ"
      },
      "id": "zvZu_DGturyJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparation"
      ],
      "metadata": {
        "id": "MVRkoqqP5SE1"
      },
      "id": "MVRkoqqP5SE1"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"sk-\"\n",
        "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
        "\n",
        "import nest_asyncio\n",
        "\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "5iP4rLUv5J1v"
      },
      "id": "5iP4rLUv5J1v",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ingest Data - Uber 공시 자료"
      ],
      "metadata": {
        "id": "vcx8K7xN5V7Z"
      },
      "id": "vcx8K7xN5V7Z"
    },
    {
      "cell_type": "code",
      "source": [
        "# NOTE: the code examples assume you're operating within a Jupyter notebook.\n",
        "# download files\n",
        "!mkdir data\n",
        "!wget \"https://www.dropbox.com/s/948jr9cfs7fgj99/UBER.zip?dl=1\" -O data/UBER.zip\n",
        "!unzip data/UBER.zip -d data"
      ],
      "metadata": {
        "id": "PkDhUPX_5bBz"
      },
      "id": "PkDhUPX_5bBz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### HTML 파일을 서식 있는 텍스트로 구문 분석하기 위해 구조화되지 않은 라이브러리를 사용합니다. LlamaHub 덕분에 우리는 Unstructured와 직접 통합하여 모든 텍스트를 LlamaIndex가 수집할 수 있는 문서 형식으로 변환할 수 있습니다."
      ],
      "metadata": {
        "id": "o1Fv_v6j5sik"
      },
      "id": "o1Fv_v6j5sik"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama-hub unstructured"
      ],
      "metadata": {
        "id": "WAoz_WaC5Jy5"
      },
      "id": "WAoz_WaC5Jy5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 그런 다음 UnstructuredReader를 사용하여 HTML 파일을 Document 개체 목록으로 구문 분석할 수 있습니다."
      ],
      "metadata": {
        "id": "B4KPlFYL6D67"
      },
      "id": "B4KPlFYL6D67"
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_hub.file.unstructured.base import UnstructuredReader\n",
        "from pathlib import Path\n",
        "\n",
        "years = [2022, 2021, 2020, 2019]\n",
        "\n",
        "loader = UnstructuredReader()\n",
        "doc_set = {}\n",
        "all_docs = []\n",
        "for year in years:\n",
        "    year_docs = loader.load_data(\n",
        "        file=Path(f\"./data/UBER/UBER_{year}.html\"), split_documents=False\n",
        "    )\n",
        "    # insert year metadata into each year\n",
        "    for d in year_docs:\n",
        "        d.metadata = {\"year\": year}\n",
        "    doc_set[year] = year_docs\n",
        "    all_docs.extend(year_docs)"
      ],
      "metadata": {
        "id": "S0ikm79G6Dq9"
      },
      "id": "S0ikm79G6Dq9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 각 연도별 벡터 지수 설정"
      ],
      "metadata": {
        "id": "rrJqrtdc6T95"
      },
      "id": "rrJqrtdc6T95"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 먼저 각 연도에 대한 벡터 인덱스를 설정합니다. 각 벡터 인덱스를 통해 특정 연도의 10-K 제출에 대해 질문할 수 있습니다.\n",
        "\n",
        "### 각 인덱스를 작성하여 디스크에 저장합니다."
      ],
      "metadata": {
        "id": "svUHw1JT6fJw"
      },
      "id": "svUHw1JT6fJw"
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize simple vector indices\n",
        "from llama_index import VectorStoreIndex, ServiceContext, StorageContext\n",
        "\n",
        "index_set = {}\n",
        "service_context = ServiceContext.from_defaults(chunk_size=512)\n",
        "for year in years:\n",
        "    storage_context = StorageContext.from_defaults()\n",
        "    cur_index = VectorStoreIndex.from_documents(\n",
        "        doc_set[year],\n",
        "        service_context=service_context,\n",
        "        storage_context=storage_context,\n",
        "    )\n",
        "    index_set[year] = cur_index\n",
        "    storage_context.persist(persist_dir=f\"./storage/{year}\")"
      ],
      "metadata": {
        "id": "N_XM0SjZ6a17"
      },
      "id": "N_XM0SjZ6a17",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 디스크에서 인덱스를 로드하려면 다음을 수행하세요."
      ],
      "metadata": {
        "id": "IttKbHiq6veu"
      },
      "id": "IttKbHiq6veu"
    },
    {
      "cell_type": "code",
      "source": [
        "# Load indices from disk\n",
        "from llama_index import load_index_from_storage, StorageContext\n",
        "\n",
        "index_set = {}\n",
        "for year in years:\n",
        "    storage_context = StorageContext.from_defaults(\n",
        "        persist_dir=f\"./storage/{year}\"\n",
        "    )\n",
        "    cur_index = load_index_from_storage(\n",
        "        storage_context, service_context=service_context\n",
        "    )\n",
        "    index_set[year] = cur_index"
      ],
      "metadata": {
        "id": "XviiHM0w60Wu"
      },
      "id": "XviiHM0w60Wu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 10-K 파일링 전체에 걸쳐 답변을 종합하기 위한 하위 질문 쿼리 엔진 설정"
      ],
      "metadata": {
        "id": "_2o4M8pR8jNI"
      },
      "id": "_2o4M8pR8jNI"
    },
    {
      "cell_type": "markdown",
      "source": [
        "우리는 4년 간의 문서에 접근할 수 있으므로 해당 연도의 10-K 문서에 관한 질문뿐만 아니라 모든 10-K 서류에 대한 분석이 필요한 질문도 할 수 있습니다.\n",
        "\n",
        "이 문제를 해결하기 위해 하위 질문 쿼리 엔진을 사용할 수 있습니다. 쿼리를 개별 벡터 인덱스로 응답하는 하위 쿼리로 분해하고 결과를 종합하여 전체 쿼리에 응답합니다."
      ],
      "metadata": {
        "id": "OlXI8mox8091"
      },
      "id": "OlXI8mox8091"
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.tools import QueryEngineTool, ToolMetadata\n",
        "\n",
        "individual_query_engine_tools = [\n",
        "    QueryEngineTool(\n",
        "        query_engine=index_set[year].as_query_engine(),\n",
        "        metadata=ToolMetadata(\n",
        "            name=f\"vector_index_{year}\",\n",
        "            description=f\"useful for when you want to answer queries about the {year} SEC 10-K for Uber\",\n",
        "        ),\n",
        "    )\n",
        "    for year in years\n",
        "]"
      ],
      "metadata": {
        "id": "-_FTolTK8pX9"
      },
      "id": "-_FTolTK8pX9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.query_engine import SubQuestionQueryEngine\n",
        "\n",
        "query_engine = SubQuestionQueryEngine.from_defaults(\n",
        "    query_engine_tools=individual_query_engine_tools,\n",
        "    service_context=service_context,\n",
        ")"
      ],
      "metadata": {
        "id": "Rg5pDHet5JVT"
      },
      "id": "Rg5pDHet5JVT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 챗봇 에이전트 설정"
      ],
      "metadata": {
        "id": "qqEWtNfW9FEg"
      },
      "id": "qqEWtNfW9FEg"
    },
    {
      "cell_type": "markdown",
      "source": [
        "우리는 LlamaIndex 데이터 에이전트를 사용하여 도구 세트에 액세스할 수 있는 외부 챗봇 에이전트를 설정합니다. 구체적으로 OpenAI API 함수 호출을 활용하는 OpenAIAgent를 사용하겠습니다. 우리는 위에서 정의한 하위 질문 쿼리 엔진을 위한 도구뿐만 아니라 각 지수(특정 연도에 해당)에 대해 이전에 정의한 별도의 도구를 사용하려고 합니다.\n",
        "\n",
        "먼저 하위 질문 쿼리 엔진에 대한 QueryEngineTool을 정의합니다."
      ],
      "metadata": {
        "id": "YSQzp56w9LtE"
      },
      "id": "YSQzp56w9LtE"
    },
    {
      "cell_type": "code",
      "source": [
        "query_engine_tool = QueryEngineTool(\n",
        "    query_engine=query_engine,\n",
        "    metadata=ToolMetadata(\n",
        "        name=\"sub_question_query_engine\",\n",
        "        description=\"useful for when you want to answer queries that require analyzing multiple SEC 10-K documents for Uber\",\n",
        "    ),\n",
        ")"
      ],
      "metadata": {
        "id": "H_o5p3UZ9X_4"
      },
      "id": "H_o5p3UZ9X_4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "그런 다음 위에서 정의한 도구를 에이전트용 단일 도구 목록으로 결합합니다."
      ],
      "metadata": {
        "id": "9BUHOG4H9dzH"
      },
      "id": "9BUHOG4H9dzH"
    },
    {
      "cell_type": "code",
      "source": [
        "tools = individual_query_engine_tools + [query_engine_tool]"
      ],
      "metadata": {
        "id": "iL54_cBQ9kwg"
      },
      "id": "iL54_cBQ9kwg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "마지막으로 위에서 정의한 도구 목록을 전달하여 OpenAIAgent.from_tools를 호출하여 에이전트를 생성합니다."
      ],
      "metadata": {
        "id": "veEwUHqB9i0k"
      },
      "id": "veEwUHqB9i0k"
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.agent import OpenAIAgent\n",
        "\n",
        "agent = OpenAIAgent.from_tools(tools, verbose=True)"
      ],
      "metadata": {
        "id": "lxdKamyz9uCs"
      },
      "id": "lxdKamyz9uCs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 에이전트 테스트"
      ],
      "metadata": {
        "id": "df6GR2809xxr"
      },
      "id": "df6GR2809xxr"
    },
    {
      "cell_type": "markdown",
      "source": [
        "이제 다양한 쿼리로 에이전트를 테스트할 수 있습니다.\n",
        "\n",
        "간단한 \"hello\" 쿼리로 테스트하면 에이전트는 어떤 도구도 사용하지 않습니다."
      ],
      "metadata": {
        "id": "bvtjYpxU92YW"
      },
      "id": "bvtjYpxU92YW"
    },
    {
      "cell_type": "code",
      "source": [
        "response = agent.chat(\"hi, i am Joon\")\n",
        "print(str(response))"
      ],
      "metadata": {
        "id": "7RjjWHUC96-6"
      },
      "id": "7RjjWHUC96-6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "특정 연도의 10-k에 관한 쿼리로 테스트하면 에이전트는 관련 벡터 인덱스 도구를 사용합니다."
      ],
      "metadata": {
        "id": "C8LpZJCk-C7G"
      },
      "id": "C8LpZJCk-C7G"
    },
    {
      "cell_type": "code",
      "source": [
        "response = agent.chat(\n",
        "    \"What were some of the biggest risk factors in 2020 for Uber?\"\n",
        ")\n",
        "print(str(response))"
      ],
      "metadata": {
        "id": "eokwUbx7-AtN"
      },
      "id": "eokwUbx7-AtN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "마지막으로 수년간 위험 요소를 비교/대조하는 쿼리로 테스트하면 에이전트는 하위 질문 쿼리 엔진 도구를 사용합니다."
      ],
      "metadata": {
        "id": "6t2z7Jsq-OB9"
      },
      "id": "6t2z7Jsq-OB9"
    },
    {
      "cell_type": "code",
      "source": [
        "cross_query_str = \"Compare/contrast the risk factors described in the Uber 10-K across years. Give answer in bullet points.\"\n",
        "\n",
        "response = agent.chat(cross_query_str)\n",
        "print(str(response))"
      ],
      "metadata": {
        "id": "T9SgsGyd-TGr"
      },
      "id": "T9SgsGyd-TGr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 챗봇 루프 설정"
      ],
      "metadata": {
        "id": "zTbHvoWG_yVB"
      },
      "id": "zTbHvoWG_yVB"
    },
    {
      "cell_type": "code",
      "source": [
        "agent = OpenAIAgent.from_tools(tools)  # verbose=False by default\n",
        "\n",
        "while True:\n",
        "    text_input = input(\"User: \")\n",
        "    if text_input == \"exit\":\n",
        "        break\n",
        "    response = agent.chat(text_input)\n",
        "    print(f\"Agent: {response}\")"
      ],
      "metadata": {
        "id": "Azy6Iy-F_wI2"
      },
      "id": "Azy6Iy-F_wI2",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "gpt_index",
      "language": "python",
      "name": "gpt_index"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}