{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNiGVPzmOzNOzCZe2t9VIAd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JSJeong-me/GPT-Web/blob/main/122-function_call_api.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### https://cookbook.openai.com/examples/how_to_call_functions_with_chat_models\n"
      ],
      "metadata": {
        "id": "es8jDdU_JJJ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai==0.28\n",
        "!pip install python-dotenv"
      ],
      "metadata": {
        "id": "LOD8ANuqgeo1",
        "outputId": "a32c2897-fdfb-4ce7-a7a4-02f775a2a650",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==0.28\n",
            "  Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.9.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2023.11.17)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
            "Installing collected packages: openai\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed openai-0.28.0\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!echo \"OPENAI_API_KEY=sk-\" >> .env"
      ],
      "metadata": {
        "id": "u3nQc-cyglgE"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!source /content/.env"
      ],
      "metadata": {
        "id": "JwKBV8lzgqnW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load environment variables from .env file\n",
        "load_dotenv()\n",
        "# Access the API key using the variable name defined in the .env file\n",
        "api_key = os.getenv(\"OPENAI_API_KEY\")"
      ],
      "metadata": {
        "id": "8fl4M1lhgsso"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f6fAcxvKGXFV",
        "outputId": "1e265f73-ce89-4afc-b7bd-eeebb0d14268",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.11.4)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy) (1.23.5)\n",
            "Requirement already satisfied: tenacity in /usr/local/lib/python3.10/dist-packages (8.2.3)\n",
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2023.11.17)\n"
          ]
        }
      ],
      "source": [
        "!pip install scipy\n",
        "!pip install tenacity\n",
        "!pip install tiktoken\n",
        "!pip install termcolor\n",
        "!pip install openai\n",
        "!pip install requests"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import openai\n",
        "import requests\n",
        "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
        "from termcolor import colored\n",
        "\n",
        "GPT_MODEL = \"gpt-3.5-turbo-0613\""
      ],
      "metadata": {
        "id": "Jtyyg_UuGe1Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the OpenAI API client\n",
        "# openai.api_key = \"sk-T\""
      ],
      "metadata": {
        "id": "r6Uev4x0HbCT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@retry(wait=wait_random_exponential(multiplier=1, max=40), stop=stop_after_attempt(3))\n",
        "def chat_completion_request(messages, functions=None, function_call=None, model=GPT_MODEL):\n",
        "    headers = {\n",
        "        \"Content-Type\": \"application/json\",\n",
        "        \"Authorization\": \"Bearer \" + openai.api_key,\n",
        "    }\n",
        "    json_data = {\"model\": model, \"messages\": messages}\n",
        "    if functions is not None:\n",
        "        json_data.update({\"functions\": functions})\n",
        "    if function_call is not None:\n",
        "        json_data.update({\"function_call\": function_call})\n",
        "    try:\n",
        "        response = requests.post(\n",
        "            \"https://api.openai.com/v1/chat/completions\",\n",
        "            headers=headers,\n",
        "            json=json_data,\n",
        "        )\n",
        "        return response\n",
        "    except Exception as e:\n",
        "        print(\"Unable to generate ChatCompletion response\")\n",
        "        print(f\"Exception: {e}\")\n",
        "        return e\n"
      ],
      "metadata": {
        "id": "U5NdHUKGGq3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pretty_print_conversation(messages):\n",
        "    role_to_color = {\n",
        "        \"system\": \"red\",\n",
        "        \"user\": \"green\",\n",
        "        \"assistant\": \"blue\",\n",
        "        \"function\": \"magenta\",\n",
        "    }\n",
        "\n",
        "    for message in messages:\n",
        "        if message[\"role\"] == \"system\":\n",
        "            print(colored(f\"system: {message['content']}\\n\", role_to_color[message[\"role\"]]))\n",
        "        elif message[\"role\"] == \"user\":\n",
        "            print(colored(f\"user: {message['content']}\\n\", role_to_color[message[\"role\"]]))\n",
        "        elif message[\"role\"] == \"assistant\" and message.get(\"function_call\"):\n",
        "            print(colored(f\"assistant: {message['function_call']}\\n\", role_to_color[message[\"role\"]]))\n",
        "        elif message[\"role\"] == \"assistant\" and not message.get(\"function_call\"):\n",
        "            print(colored(f\"assistant: {message['content']}\\n\", role_to_color[message[\"role\"]]))\n",
        "        elif message[\"role\"] == \"function\":\n",
        "            print(colored(f\"function ({message['name']}): {message['content']}\\n\", role_to_color[message[\"role\"]]))\n"
      ],
      "metadata": {
        "id": "BaqOWqbrGuQj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "functions = [\n",
        "    {\n",
        "        \"name\": \"get_current_weather\",\n",
        "        \"description\": \"Get the current weather\",\n",
        "        \"parameters\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"location\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
        "                },\n",
        "                \"format\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"enum\": [\"celsius\", \"fahrenheit\"],\n",
        "                    \"description\": \"The temperature unit to use. Infer this from the users location.\",\n",
        "                },\n",
        "            },\n",
        "            \"required\": [\"location\", \"format\"],\n",
        "        },\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"get_n_day_weather_forecast\",\n",
        "        \"description\": \"Get an N-day weather forecast\",\n",
        "        \"parameters\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"location\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
        "                },\n",
        "                \"format\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"enum\": [\"celsius\", \"fahrenheit\"],\n",
        "                    \"description\": \"The temperature unit to use. Infer this from the users location.\",\n",
        "                },\n",
        "                \"num_days\": {\n",
        "                    \"type\": \"integer\",\n",
        "                    \"description\": \"The number of days to forecast\",\n",
        "                }\n",
        "            },\n",
        "            \"required\": [\"location\", \"format\", \"num_days\"]\n",
        "        },\n",
        "    },\n",
        "]"
      ],
      "metadata": {
        "id": "XdFiRZsWGxKg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = []\n",
        "messages.append({\"role\": \"system\", \"content\": \"Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\"})\n",
        "messages.append({\"role\": \"user\", \"content\": \"What's the weather like today\"})\n",
        "chat_response = chat_completion_request(\n",
        "    messages, functions=functions\n",
        ")\n",
        "assistant_message = chat_response.json()[\"choices\"][0][\"message\"]\n",
        "messages.append(assistant_message)\n",
        "assistant_message\n"
      ],
      "metadata": {
        "id": "9h-xs352G9uj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_response.json()"
      ],
      "metadata": {
        "id": "tRiitlyih3qI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response_json = chat_response.json()\n",
        "if 'choices' in response_json:\n",
        "    assistant_message = response_json[\"choices\"][0][\"message\"]\n",
        "else:\n",
        "    # Handle the absence of 'choices' key\n",
        "    print(\"Key 'choices' not found in the response.\")\n"
      ],
      "metadata": {
        "id": "bFyX91mehsF7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages.append({\"role\": \"user\", \"content\": \"I'm in Glasgow, Scotland.\"})\n",
        "chat_response = chat_completion_request(\n",
        "    messages, functions=functions\n",
        ")\n",
        "assistant_message = chat_response.json()[\"choices\"][0][\"message\"]\n",
        "messages.append(assistant_message)\n",
        "assistant_message\n"
      ],
      "metadata": {
        "id": "9ZZP2rqNHz2_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = []\n",
        "messages.append({\"role\": \"system\", \"content\": \"Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\"})\n",
        "messages.append({\"role\": \"user\", \"content\": \"what is the weather going to be like in Glasgow, Scotland over the next x days\"})\n",
        "chat_response = chat_completion_request(\n",
        "    messages, functions=functions\n",
        ")\n",
        "assistant_message = chat_response.json()[\"choices\"][0][\"message\"]\n",
        "messages.append(assistant_message)\n",
        "assistant_message\n"
      ],
      "metadata": {
        "id": "ECl3AjLKIOBr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages.append({\"role\": \"user\", \"content\": \"5 days\"})\n",
        "chat_response = chat_completion_request(\n",
        "    messages, functions=functions\n",
        ")\n",
        "chat_response.json()[\"choices\"][0]\n"
      ],
      "metadata": {
        "id": "_3eSQw6jIcNV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# in this cell we force the model to use get_n_day_weather_forecast\n",
        "messages = []\n",
        "messages.append({\"role\": \"system\", \"content\": \"Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\"})\n",
        "messages.append({\"role\": \"user\", \"content\": \"Give me a weather report for Toronto, Canada.\"})\n",
        "chat_response = chat_completion_request(\n",
        "    messages, functions=functions, function_call={\"name\": \"get_n_day_weather_forecast\"}\n",
        ")\n",
        "chat_response.json()[\"choices\"][0][\"message\"]\n"
      ],
      "metadata": {
        "id": "OBDpGW0OImRw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# if we don't force the model to use get_n_day_weather_forecast it may not\n",
        "messages = []\n",
        "messages.append({\"role\": \"system\", \"content\": \"Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\"})\n",
        "messages.append({\"role\": \"user\", \"content\": \"Give me a weather report for Toronto, Canada.\"})\n",
        "chat_response = chat_completion_request(\n",
        "    messages, functions=functions\n",
        ")\n",
        "chat_response.json()[\"choices\"][0][\"message\"]\n"
      ],
      "metadata": {
        "id": "1qIz-oJuIsHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NnbiLLDfJO60"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4M_7uOYRJOrG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}