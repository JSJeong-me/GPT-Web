{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOtvnwA1JW+1IdFUGsnzmCr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JSJeong-me/GPT-Web/blob/main/201-LlamaIndex-customization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama-index"
      ],
      "metadata": {
        "id": "dWsNyQv1MukU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://docs.llamaindex.ai/en/stable/getting_started/customization.html"
      ],
      "metadata": {
        "id": "Gq0P5IxdMKuc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# from llama_index import VectorStoreIndex, SimpleWebPageReader\n",
        "# Enter your OpenAI key below:\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"sk-\""
      ],
      "metadata": {
        "id": "0DUEhmN_M7ts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir data"
      ],
      "metadata": {
        "id": "clhGCqC3NGsr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fvrviUSRMKDf"
      },
      "outputs": [],
      "source": [
        "from llama_index import VectorStoreIndex, SimpleDirectoryReader\n",
        "\n",
        "documents = SimpleDirectoryReader(\"data\").load_data()\n",
        "index = VectorStoreIndex.from_documents(documents)\n",
        "query_engine = index.as_query_engine()\n",
        "response = query_engine.query(\"What did the author do growing up?\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "“내 문서를 더 작은 Chunk로 분석하고 싶습니다.”"
      ],
      "metadata": {
        "id": "WS0juZ5CNqqd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index import ServiceContext\n",
        "\n",
        "service_context = ServiceContext.from_defaults(chunk_size=1000)"
      ],
      "metadata": {
        "id": "JMzgV-JqPwn3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index import VectorStoreIndex, SimpleDirectoryReader\n",
        "\n",
        "documents = SimpleDirectoryReader(\"data\").load_data()\n",
        "index = VectorStoreIndex.from_documents(\n",
        "    documents, service_context=service_context\n",
        ")\n",
        "query_engine = index.as_query_engine()\n",
        "response = query_engine.query(\"What did the author do growing up?\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "LT_etlKfP0xo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "“다른 벡터 스토어를 사용하고 싶습니다”"
      ],
      "metadata": {
        "id": "Z7JBr9E_P7oI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install chromadb"
      ],
      "metadata": {
        "id": "YwVlptOoQBUe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import chromadb\n",
        "from llama_index.vector_stores import ChromaVectorStore\n",
        "from llama_index import StorageContext\n",
        "\n",
        "chroma_client = chromadb.PersistentClient()\n",
        "chroma_collection = chroma_client.create_collection(\"quickstart\")\n",
        "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
        "storage_context = StorageContext.from_defaults(vector_store=vector_store)"
      ],
      "metadata": {
        "id": "3jqDKPVxP9h5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index import VectorStoreIndex, SimpleDirectoryReader\n",
        "\n",
        "documents = SimpleDirectoryReader(\"data\").load_data()\n",
        "index = VectorStoreIndex.from_documents(\n",
        "    documents, storage_context=storage_context\n",
        ")\n",
        "query_engine = index.as_query_engine()\n",
        "response = query_engine.query(\"What did the author do growing up?\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "JkNxmdebQmfs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "“쿼리할 때 더 많은 컨텍스트를 검색하고 싶습니다.”"
      ],
      "metadata": {
        "id": "C1KUIpBNQpWl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index import VectorStoreIndex, SimpleDirectoryReader\n",
        "\n",
        "documents = SimpleDirectoryReader(\"data\").load_data()\n",
        "index = VectorStoreIndex.from_documents(documents)\n",
        "query_engine = index.as_query_engine(similarity_top_k=5)\n",
        "response = query_engine.query(\"What did the author do growing up?\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "kvP58lE8QtsP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "“다른 LLM을 이용하고 싶어요”"
      ],
      "metadata": {
        "id": "rksKY3VgQzT4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index import ServiceContext\n",
        "from llama_index.llms import PaLM\n",
        "\n",
        "service_context = ServiceContext.from_defaults(llm=PaLM())"
      ],
      "metadata": {
        "id": "qK_7H3wKQyuv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index import VectorStoreIndex, SimpleDirectoryReader\n",
        "\n",
        "documents = SimpleDirectoryReader(\"data\").load_data()\n",
        "index = VectorStoreIndex.from_documents(documents)\n",
        "query_engine = index.as_query_engine(service_context=service_context)\n",
        "response = query_engine.query(\"What did the author do growing up?\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "Yvu-2vBdQ-AP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "“다른 응답 모드를 사용하고 싶습니다”"
      ],
      "metadata": {
        "id": "bJKuyNPvRBQQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index import VectorStoreIndex, SimpleDirectoryReader\n",
        "\n",
        "documents = SimpleDirectoryReader(\"data\").load_data()\n",
        "index = VectorStoreIndex.from_documents(documents)\n",
        "query_engine = index.as_query_engine(response_mode=\"tree_summarize\")\n",
        "response = query_engine.query(\"What did the author do growing up?\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "x3p59hcTRGGy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "“응답을 다시 스트리밍하고 싶습니다.”"
      ],
      "metadata": {
        "id": "dEX4NTTWRKqb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index import VectorStoreIndex, SimpleDirectoryReader\n",
        "\n",
        "documents = SimpleDirectoryReader(\"data\").load_data()\n",
        "index = VectorStoreIndex.from_documents(documents)\n",
        "query_engine = index.as_query_engine(streaming=True)\n",
        "response = query_engine.query(\"What did the author do growing up?\")\n",
        "response.print_response_stream()"
      ],
      "metadata": {
        "id": "0MpsP7xNRPdc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "“Q&A 대신 챗봇을 원해요”"
      ],
      "metadata": {
        "id": "g8jt5MuZRT-m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index import VectorStoreIndex, SimpleDirectoryReader\n",
        "\n",
        "documents = SimpleDirectoryReader(\"data\").load_data()\n",
        "index = VectorStoreIndex.from_documents(documents)\n",
        "query_engine = index.as_chat_engine()\n",
        "response = query_engine.chat(\"What did the author do growing up?\")\n",
        "print(response)\n",
        "\n",
        "response = query_engine.chat(\"Oh interesting, tell me more.\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "-2MrvOluRZ3W"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}