{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JSJeong-me/GPT-Web/blob/main/104-Semantic_text_search_using_embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5cgXhHMOyFr"
      },
      "source": [
        "## Semantic text search using embeddings\n",
        "\n",
        "We can search through all our reviews semantically in a very efficient manner and at very low cost, by embedding our search query, and then finding the most similar reviews. The dataset is created in the [Get_embeddings_from_dataset Notebook](Get_embeddings_from_dataset.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai\n",
        "!pip install python-dotenv\n",
        "!pip install tiktoken"
      ],
      "metadata": {
        "id": "hQUHcMC8QDwn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show openai | grep Version"
      ],
      "metadata": {
        "id": "eIxJDze8Q1zn",
        "outputId": "eaac46d6-be6e-4b26-af22-5d87a1ee39c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Version: 1.3.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!echo \"OPENAI_API_KEY=sk-\" >> .env\n",
        "!source /content/.env"
      ],
      "metadata": {
        "id": "HYtYvy_UQSJ7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load environment variables from .env file\n",
        "load_dotenv()\n",
        "# Access the API key using the variable name defined in the .env file\n",
        "api_key = os.getenv(\"OPENAI_API_KEY\")"
      ],
      "metadata": {
        "id": "th0LxqwmQXLK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir utils"
      ],
      "metadata": {
        "id": "of__WFg4PVKG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "FABen0nGOyFw"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from ast import literal_eval\n",
        "\n",
        "datafile_path = \"fine_food_reviews_with_embeddings_1k.csv\"\n",
        "\n",
        "df = pd.read_csv(datafile_path)\n",
        "df[\"embedding\"] = df.embedding.apply(literal_eval).apply(np.array)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNHdUq_sOyFy"
      },
      "source": [
        "Here we compare the cosine similarity of the embeddings of the query and the documents, and show top_n best matches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "mYFjP8tsOyFz",
        "outputId": "1608550c-80cb-4827-9533-3ccfab2ba812",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Good Buy:  I liked the beans. They were vacuum sealed, plump and moist. Would recommend them for any use. I personally split and stuck them in some vodka to make vanilla extract. Yum!\n",
            "\n",
            "Jamaican Blue beans:  Excellent coffee bean for roasting. Our family just purchased another 5 pounds for more roasting. Plenty of flavor and mild on acidity when roasted to a dark brown bean and befor\n",
            "\n",
            "Delicious!:  I enjoy this white beans seasoning, it gives a rich flavor to the beans I just love it, my mother in law didn't know about this Zatarain's brand and now she is traying different seasoning\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from utils.embeddings_utils import get_embedding, cosine_similarity\n",
        "\n",
        "# search through the reviews for a specific product\n",
        "def search_reviews(df, product_description, n=3, pprint=True):\n",
        "    product_embedding = get_embedding(\n",
        "        product_description,\n",
        "        model=\"text-embedding-ada-002\"\n",
        "    )\n",
        "    df[\"similarity\"] = df.embedding.apply(lambda x: cosine_similarity(x, product_embedding))\n",
        "\n",
        "    results = (\n",
        "        df.sort_values(\"similarity\", ascending=False)\n",
        "        .head(n)\n",
        "        .combined.str.replace(\"Title: \", \"\")\n",
        "        .str.replace(\"; Content:\", \": \")\n",
        "    )\n",
        "    if pprint:\n",
        "        for r in results:\n",
        "            print(r[:200])\n",
        "            print()\n",
        "    return results\n",
        "\n",
        "\n",
        "results = search_reviews(df, \"delicious beans\", n=3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "L-n67j1mOyF0",
        "outputId": "f56b13ab-b80d-469a-a46e-bee87c197358",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tasty and Quick Pasta:  Barilla Whole Grain Fusilli with Vegetable Marinara is tasty and has an excellent chunky vegetable marinara.  I just wish there was more of it.  If you aren't starving or on a \n",
            "\n",
            "sooo good:  tastes so good. Worth the money. My boyfriend hates wheat pasta and LOVES this. cooks fast tastes great.I love this brand and started buying more of their pastas. Bulk is best.\n",
            "\n",
            "Handy:  Love the idea of ready in a minute pasta and for that alone this product gets praise.  The pasta is whole grain so that's a big plus and it actually comes out al dente.  The vegetable marinara\n",
            "\n"
          ]
        }
      ],
      "source": [
        "results = search_reviews(df, \"whole wheat pasta\", n=3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QO8fic1mOyF1"
      },
      "source": [
        "We can search through these reviews easily. To speed up computation, we can use a special algorithm, aimed at faster search through embeddings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "u2voEdBVOyF1",
        "outputId": "92128190-f99e-487d-dca5-c7cbf07ed35d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "great product, poor delivery:  The coffee is excellent and I am a repeat buyer.  Problem this time was with the UPS delivery.  They left the box in front of my garage door in the middle of the drivewa\n",
            "\n"
          ]
        }
      ],
      "source": [
        "results = search_reviews(df, \"bad delivery\", n=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FaoASC5eOyF2"
      },
      "source": [
        "As we can see, this can immediately deliver a lot of value. In this example we show being able to quickly find the examples of delivery failures."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "MtsPUPAuOyF3",
        "outputId": "fbd626cb-c314-477b-86a6-66a250b11225",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extremely dissapointed:  Hi,<br />I am very disappointed with the past shipment I received of the ONE coconut water. 3 of the boxes were leaking and the coconut water was spoiled.<br /><br />Thanks.<b\n",
            "\n"
          ]
        }
      ],
      "source": [
        "results = search_reviews(df, \"spoilt\", n=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "tLDq-bhWOyF3",
        "outputId": "dbb1fcd1-5255-4144-d14a-559c1e23a02b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Good food:  The only dry food my queen cat will eat. Helps prevent hair balls. Good packaging. Arrives promptly. Recommended by a friend who sells pet food.\n",
            "\n",
            "The cats like it:  My 7 cats like this food but it is a little yucky for the human. Pieces of mackerel swimming in a dark broth. It is billed as a \"complete\" food and contains carrots, peas and pasta.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "results = search_reviews(df, \"pet food\", n=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import textwrap as tr\n",
        "from typing import List, Optional\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "from scipy import spatial\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.metrics import average_precision_score, precision_recall_curve\n",
        "from tenacity import retry, stop_after_attempt, wait_random_exponential\n",
        "\n",
        "import openai\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "@retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(6))\n",
        "def get_embedding(text: str, model=\"text-similarity-davinci-001\", **kwargs) -> List[float]:\n",
        "\n",
        "    # replace newlines, which can negatively affect performance.\n",
        "    text = text.replace(\"\\n\", \" \")\n",
        "\n",
        "    response = openai.embeddings.create(input=[text], model=model, **kwargs)\n",
        "\n",
        "    return response.data[0].embedding\n",
        "\n",
        "\n",
        "@retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(6))\n",
        "async def aget_embedding(\n",
        "    text: str, model=\"text-similarity-davinci-001\", **kwargs\n",
        ") -> List[float]:\n",
        "\n",
        "    # replace newlines, which can negatively affect performance.\n",
        "    text = text.replace(\"\\n\", \" \")\n",
        "\n",
        "    return (await openai.embeddings.create(input=[text], model=model, **kwargs))[\"data\"][0][\n",
        "        \"embedding\"\n",
        "    ]\n",
        "\n",
        "\n",
        "@retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(6))\n",
        "def get_embeddings(\n",
        "    list_of_text: List[str], model=\"text-similarity-babbage-001\", **kwargs\n",
        ") -> List[List[float]]:\n",
        "    assert len(list_of_text) <= 2048, \"The batch size should not be larger than 2048.\"\n",
        "\n",
        "    # replace newlines, which can negatively affect performance.\n",
        "    list_of_text = [text.replace(\"\\n\", \" \") for text in list_of_text]\n",
        "\n",
        "    data = openai.embeddings.create(input=list_of_text, model=model, **kwargs).data\n",
        "    return [d.embedding for d in data]\n",
        "\n",
        "\n",
        "@retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(6))\n",
        "async def aget_embeddings(\n",
        "    list_of_text: List[str], model=\"text-similarity-babbage-001\", **kwargs\n",
        ") -> List[List[float]]:\n",
        "    assert len(list_of_text) <= 2048, \"The batch size should not be larger than 2048.\"\n",
        "\n",
        "    # replace newlines, which can negatively affect performance.\n",
        "    list_of_text = [text.replace(\"\\n\", \" \") for text in list_of_text]\n",
        "\n",
        "    data = (await openai.embeddings.create(input=list_of_text, model=model, **kwargs)).data\n",
        "    return [d.embedding for d in data]\n",
        "\n",
        "\n",
        "def cosine_similarity(a, b):\n",
        "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
        "\n",
        "\n",
        "def plot_multiclass_precision_recall(\n",
        "    y_score, y_true_untransformed, class_list, classifier_name\n",
        "):\n",
        "    \"\"\"\n",
        "    Precision-Recall plotting for a multiclass problem. It plots average precision-recall, per class precision recall and reference f1 contours.\n",
        "\n",
        "    Code slightly modified, but heavily based on https://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html\n",
        "    \"\"\"\n",
        "    n_classes = len(class_list)\n",
        "    y_true = pd.concat(\n",
        "        [(y_true_untransformed == class_list[i]) for i in range(n_classes)], axis=1\n",
        "    ).values\n",
        "\n",
        "    # For each class\n",
        "    precision = dict()\n",
        "    recall = dict()\n",
        "    average_precision = dict()\n",
        "    for i in range(n_classes):\n",
        "        precision[i], recall[i], _ = precision_recall_curve(y_true[:, i], y_score[:, i])\n",
        "        average_precision[i] = average_precision_score(y_true[:, i], y_score[:, i])\n",
        "\n",
        "    # A \"micro-average\": quantifying score on all classes jointly\n",
        "    precision_micro, recall_micro, _ = precision_recall_curve(\n",
        "        y_true.ravel(), y_score.ravel()\n",
        "    )\n",
        "    average_precision_micro = average_precision_score(y_true, y_score, average=\"micro\")\n",
        "    print(\n",
        "        str(classifier_name)\n",
        "        + \" - Average precision score over all classes: {0:0.2f}\".format(\n",
        "            average_precision_micro\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # setup plot details\n",
        "    plt.figure(figsize=(9, 10))\n",
        "    f_scores = np.linspace(0.2, 0.8, num=4)\n",
        "    lines = []\n",
        "    labels = []\n",
        "    for f_score in f_scores:\n",
        "        x = np.linspace(0.01, 1)\n",
        "        y = f_score * x / (2 * x - f_score)\n",
        "        (l,) = plt.plot(x[y >= 0], y[y >= 0], color=\"gray\", alpha=0.2)\n",
        "        plt.annotate(\"f1={0:0.1f}\".format(f_score), xy=(0.9, y[45] + 0.02))\n",
        "\n",
        "    lines.append(l)\n",
        "    labels.append(\"iso-f1 curves\")\n",
        "    (l,) = plt.plot(recall_micro, precision_micro, color=\"gold\", lw=2)\n",
        "    lines.append(l)\n",
        "    labels.append(\n",
        "        \"average Precision-recall (auprc = {0:0.2f})\" \"\".format(average_precision_micro)\n",
        "    )\n",
        "\n",
        "    for i in range(n_classes):\n",
        "        (l,) = plt.plot(recall[i], precision[i], lw=2)\n",
        "        lines.append(l)\n",
        "        labels.append(\n",
        "            \"Precision-recall for class `{0}` (auprc = {1:0.2f})\"\n",
        "            \"\".format(class_list[i], average_precision[i])\n",
        "        )\n",
        "\n",
        "    fig = plt.gcf()\n",
        "    fig.subplots_adjust(bottom=0.25)\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel(\"Recall\")\n",
        "    plt.ylabel(\"Precision\")\n",
        "    plt.title(f\"{classifier_name}: Precision-Recall curve for each class\")\n",
        "    plt.legend(lines, labels)\n",
        "\n",
        "\n",
        "def distances_from_embeddings(\n",
        "    query_embedding: List[float],\n",
        "    embeddings: List[List[float]],\n",
        "    distance_metric=\"cosine\",\n",
        ") -> List[List]:\n",
        "    \"\"\"Return the distances between a query embedding and a list of embeddings.\"\"\"\n",
        "    distance_metrics = {\n",
        "        \"cosine\": spatial.distance.cosine,\n",
        "        \"L1\": spatial.distance.cityblock,\n",
        "        \"L2\": spatial.distance.euclidean,\n",
        "        \"Linf\": spatial.distance.chebyshev,\n",
        "    }\n",
        "    distances = [\n",
        "        distance_metrics[distance_metric](query_embedding, embedding)\n",
        "        for embedding in embeddings\n",
        "    ]\n",
        "    return distances\n",
        "\n",
        "\n",
        "def indices_of_nearest_neighbors_from_distances(distances) -> np.ndarray:\n",
        "    \"\"\"Return a list of indices of nearest neighbors from a list of distances.\"\"\"\n",
        "    return np.argsort(distances)\n",
        "\n",
        "\n",
        "def pca_components_from_embeddings(\n",
        "    embeddings: List[List[float]], n_components=2\n",
        ") -> np.ndarray:\n",
        "    \"\"\"Return the PCA components of a list of embeddings.\"\"\"\n",
        "    pca = PCA(n_components=n_components)\n",
        "    array_of_embeddings = np.array(embeddings)\n",
        "    return pca.fit_transform(array_of_embeddings)\n",
        "\n",
        "\n",
        "def tsne_components_from_embeddings(\n",
        "    embeddings: List[List[float]], n_components=2, **kwargs\n",
        ") -> np.ndarray:\n",
        "    \"\"\"Returns t-SNE components of a list of embeddings.\"\"\"\n",
        "    # use better defaults if not specified\n",
        "    if \"init\" not in kwargs.keys():\n",
        "        kwargs[\"init\"] = \"pca\"\n",
        "    if \"learning_rate\" not in kwargs.keys():\n",
        "        kwargs[\"learning_rate\"] = \"auto\"\n",
        "    tsne = TSNE(n_components=n_components, **kwargs)\n",
        "    array_of_embeddings = np.array(embeddings)\n",
        "    return tsne.fit_transform(array_of_embeddings)\n",
        "\n",
        "\n",
        "def chart_from_components(\n",
        "    components: np.ndarray,\n",
        "    labels: Optional[List[str]] = None,\n",
        "    strings: Optional[List[str]] = None,\n",
        "    x_title=\"Component 0\",\n",
        "    y_title=\"Component 1\",\n",
        "    mark_size=5,\n",
        "    **kwargs,\n",
        "):\n",
        "    \"\"\"Return an interactive 2D chart of embedding components.\"\"\"\n",
        "    empty_list = [\"\" for _ in components]\n",
        "    data = pd.DataFrame(\n",
        "        {\n",
        "            x_title: components[:, 0],\n",
        "            y_title: components[:, 1],\n",
        "            \"label\": labels if labels else empty_list,\n",
        "            \"string\": [\"<br>\".join(tr.wrap(string, width=30)) for string in strings]\n",
        "            if strings\n",
        "            else empty_list,\n",
        "        }\n",
        "    )\n",
        "    chart = px.scatter(\n",
        "        data,\n",
        "        x=x_title,\n",
        "        y=y_title,\n",
        "        color=\"label\" if labels else None,\n",
        "        symbol=\"label\" if labels else None,\n",
        "        hover_data=[\"string\"] if strings else None,\n",
        "        **kwargs,\n",
        "    ).update_traces(marker=dict(size=mark_size))\n",
        "    return chart\n",
        "\n",
        "\n",
        "def chart_from_components_3D(\n",
        "    components: np.ndarray,\n",
        "    labels: Optional[List[str]] = None,\n",
        "    strings: Optional[List[str]] = None,\n",
        "    x_title: str = \"Component 0\",\n",
        "    y_title: str = \"Component 1\",\n",
        "    z_title: str = \"Compontent 2\",\n",
        "    mark_size: int = 5,\n",
        "    **kwargs,\n",
        "):\n",
        "    \"\"\"Return an interactive 3D chart of embedding components.\"\"\"\n",
        "    empty_list = [\"\" for _ in components]\n",
        "    data = pd.DataFrame(\n",
        "        {\n",
        "            x_title: components[:, 0],\n",
        "            y_title: components[:, 1],\n",
        "            z_title: components[:, 2],\n",
        "            \"label\": labels if labels else empty_list,\n",
        "            \"string\": [\"<br>\".join(tr.wrap(string, width=30)) for string in strings]\n",
        "            if strings\n",
        "            else empty_list,\n",
        "        }\n",
        "    )\n",
        "    chart = px.scatter_3d(\n",
        "        data,\n",
        "        x=x_title,\n",
        "        y=y_title,\n",
        "        z=z_title,\n",
        "        color=\"label\" if labels else None,\n",
        "        symbol=\"label\" if labels else None,\n",
        "        hover_data=[\"string\"] if strings else None,\n",
        "        **kwargs,\n",
        "    ).update_traces(marker=dict(size=mark_size))\n",
        "    return chart"
      ],
      "metadata": {
        "id": "7GIO3vRKSfrc"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "365536dcbde60510dc9073d6b991cd35db2d9bac356a11f5b64279a5e6708b97"
      }
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}