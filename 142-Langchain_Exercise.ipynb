{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JSJeong-me/GPT-Web/blob/main/142-Langchain_Exercise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 환경설정\n",
        "a) 필요한 라이브러리 설치하기\n",
        "- langchain과 openai 패키지를 설치합니다"
      ],
      "metadata": {
        "id": "zkuAzT3-WZRv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JLwy2CFyHLiR"
      },
      "outputs": [],
      "source": [
        "!pip install langchain\n",
        "!pip install openai==0.28\n",
        "!pip install python-dotenv"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "b) OpenAI API 키 설정하기\n",
        "- export를 통해 환경변수를 설정하거나\n",
        "- 파라미터로 openai_api_key를 전달할 수 있음"
      ],
      "metadata": {
        "id": "z7AggsexWj9A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!echo \"OPENAI_API_KEY=sk-\" >> .env\n",
        "!source /content/.env"
      ],
      "metadata": {
        "id": "iubYeRFQHdDI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load environment variables from .env file\n",
        "load_dotenv()\n",
        "# Access the API key using the variable name defined in the .env file\n",
        "api_key = os.getenv(\"OPENAI_API_KEY\")"
      ],
      "metadata": {
        "id": "oEtiafFGBPqI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1) LLM 호출하기"
      ],
      "metadata": {
        "id": "qCzp7Ix4W26e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "a) ChatOpenAI (ChatGPT) 호출하기"
      ],
      "metadata": {
        "id": "d4xNRve8XA-C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "chat_model = ChatOpenAI(openai_api_key=api_key)\n",
        "chat_model.predict(\"잠이 안 올 때는 어떻게 하면 좋을지 대답해줘\")"
      ],
      "metadata": {
        "id": "ErhRuEm5IGGg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "b) Message 객체를 활용하여 ChatGPT 호출하기"
      ],
      "metadata": {
        "id": "ZEQGZGZxXNRO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.schema import HumanMessage\n",
        "\n",
        "text = \"잠이 안 올 때는 어떻게 하면 좋을지 대답해줘\"\n",
        "messages = [HumanMessage(content=text)]\n",
        "chat_model.predict_messages(messages, temperature = 0.1)"
      ],
      "metadata": {
        "id": "fTLjJ3Uoa2Sm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2) Prompt Template 작성하기"
      ],
      "metadata": {
        "id": "R2a9X9dlXVLH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "a) 기본 formatting 활용하기"
      ],
      "metadata": {
        "id": "fFEgfV3CY_IO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "my_template = \"\"\"아래의 질문에 대해 한 줄로 간결하고 친절하게 답변하세요.\n",
        "질문: {question}\"\"\"\n",
        "\n",
        "prompt = PromptTemplate.from_template(my_template)\n",
        "prompt.format(question=\"잠이 안 올 때는 어떻게 하면 좋을지 대답해줘\")\n",
        "\n",
        "chat_model.predict(prompt.format(question=\"잠이 안 올 때는 어떻게 하면 좋을지 대답해줘\"))"
      ],
      "metadata": {
        "id": "HL8MiOXtdr4j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "b) ChatMessageTemplate 활용하기"
      ],
      "metadata": {
        "id": "bfT6X_0WZBVq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts.chat import (\n",
        "    ChatPromptTemplate,\n",
        "    SystemMessagePromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        ")\n",
        "\n",
        "#시스템 역할 지정하기\n",
        "template = \"\"\"\n",
        "You are a helpful assistant to help teenagers learn {output_language}.\n",
        "Answer the question in <{output_language}> within 1~2 sentences.\n",
        "YOU MUST USE <{output_language}> TO ANSWER THE QUESTION.\n",
        "Question:\"\"\"\n",
        "\n",
        "system_message_prompt = SystemMessagePromptTemplate.from_template(template)\n",
        "human_template = \"{text}\"\n",
        "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
        "\n",
        "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
        "\n",
        "chat_prompt.format_messages(output_language=\"English\",\n",
        "                            text=\"잠이 안 올 때는 어떻게 하면 좋을지 대답해줘\")"
      ],
      "metadata": {
        "id": "FH9qUNqHZE9n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = chat_prompt.format_messages(input_language=\"한국어\",\n",
        "                            output_language=\"영어\",\n",
        "                            text=\"잠이 안 올 때는 어떻게 하면 좋을지 대답해줘\")\n",
        "\n",
        "chat_model.predict_messages(query)"
      ],
      "metadata": {
        "id": "jmWDALf1ZO2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = chat_prompt.format_messages(output_language=\"Chinese\",\n",
        "                            text=\"잠이 안 올 때는 어떻게 하면 좋을지 대답해줘\")\n",
        "\n",
        "chat_model.predict_messages(query)"
      ],
      "metadata": {
        "id": "jdyKP_YOaqqf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3) OutputParser 활용하기"
      ],
      "metadata": {
        "id": "8LeltbKDeln0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.schema import BaseOutputParser\n",
        "\n",
        "class CommaSeparatedListOutputParser(BaseOutputParser):\n",
        "    \"\"\"LLM 아웃풋에 있는 ','를 분리해서 리턴하는 파서.\"\"\"\n",
        "\n",
        "\n",
        "    def parse(self, text: str):\n",
        "        return text.strip().split(\", \")\n",
        "\n",
        "CommaSeparatedListOutputParser().parse(\"아기, 여우\")"
      ],
      "metadata": {
        "id": "aSGTruZ_bUCZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4) LLMChain으로 조합하기\n",
        "All-In-One !!!!\n",
        "\n"
      ],
      "metadata": {
        "id": "OanOEvqGcUFJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.prompts.chat import (\n",
        "    ChatPromptTemplate,\n",
        "    SystemMessagePromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        ")\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.schema import BaseOutputParser\n",
        "\n",
        "class CommaSeparatedListOutputParser(BaseOutputParser):\n",
        "    \"\"\"LLM 아웃풋에 있는 ','를 분리해서 리턴하는 파서.\"\"\"\n",
        "\n",
        "\n",
        "    def parse(self, text: str):\n",
        "        return text.strip().split(\", \")\n",
        "\n",
        "template = \"\"\"\n",
        "너는 5세 아이의 낱말놀이를 도와주는 AI야.\n",
        "아이가 어떤 카테고리에 해당하는 개체들을 말해달라고 <질문>을 하면\n",
        "해당 카테고리에 해당하는 단어들을 5개 나열해야 해.\n",
        "이때 각 단어는 반드시 comma(,)로 분리해서 대답해주고, 이외의 말은 하지 마.\n",
        "\n",
        "질문:\"\"\"\n",
        "system_message_prompt = SystemMessagePromptTemplate.from_template(template)\n",
        "human_template = \"{text}\"\n",
        "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
        "\n",
        "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
        "\n",
        "chain = LLMChain(\n",
        "    llm=ChatOpenAI(openai_api_key = api_key),\n",
        "    prompt=chat_prompt,\n",
        "    output_parser=CommaSeparatedListOutputParser()\n",
        ")\n",
        "chain.run(\"동물에 대해 공부하고 싶어\")"
      ],
      "metadata": {
        "id": "ykSTgvHsedI0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}