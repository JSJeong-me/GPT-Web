{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JSJeong-me/GPT-Web/blob/main/141-Llamaindex01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3bf01a75-a01b-472e-bc0c-9fe97658eb46",
      "metadata": {
        "id": "3bf01a75-a01b-472e-bc0c-9fe97658eb46"
      },
      "source": [
        "## LlamaIndex <> Langchain Integrations\n",
        "\n",
        "이 데모 노트북은 LlamaIndex와 Langchain 간의 통합을 제공할 수 있는 방법을 보여줍니다. 다음 예제를 제공합니다.:\n",
        "- Langchain 에이전트와 함께 호출 가능한 도구로 LlamaIndex 사용\n",
        "- LlamaIndex를 메모리 모듈로 사용 이를 통해 Langchain 챗봇에 임의의 양의 대화 기록을 삽입할 수 있습니다!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain langchain-core langchain-community python-dotenv\n",
        "!pip install openai==0.28"
      ],
      "metadata": {
        "id": "Ol6-Nyqwk86O"
      },
      "id": "Ol6-Nyqwk86O",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama-index pypdf"
      ],
      "metadata": {
        "id": "Qu8kWA3dlPH7"
      },
      "id": "Qu8kWA3dlPH7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import openai\n",
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "openai.api_key  = os.environ[\"OPENAI_API_KEY\"]"
      ],
      "metadata": {
        "id": "zYrBeA8GNDoO"
      },
      "id": "zYrBeA8GNDoO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1568569",
      "metadata": {
        "id": "c1568569"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "import sys\n",
        "\n",
        "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
        "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb9177a4-9cb7-4211-b463-121d850b5917",
      "metadata": {
        "id": "bb9177a4-9cb7-4211-b463-121d850b5917"
      },
      "source": [
        "#### Using LlamaIndex as a Callable Tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12af1b0e-983f-4fc1-b5b4-2edeb2e8f07e",
      "metadata": {
        "id": "12af1b0e-983f-4fc1-b5b4-2edeb2e8f07e"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import Tool\n",
        "from langchain.chains.conversation.memory import ConversationBufferMemory\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.agents import initialize_agent\n",
        "\n",
        "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir data"
      ],
      "metadata": {
        "id": "KCwlcBbUmA26"
      },
      "id": "KCwlcBbUmA26",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "\n",
        "url = 'https://github.com/JSJeong-me/GPT-Web/raw/main/images/paul_graham_essay.txt'\n",
        "filename = './data/paul_graham_essay.txt'\n",
        "\n",
        "urllib.request.urlretrieve(url, filename)\n",
        "\n",
        "# 파일 내용 확인 (처음 10줄 출력)\n",
        "with open(filename, 'r', encoding='utf-8') as f:\n",
        "    for _ in range(10):\n",
        "        print(f.readline().rstrip())\n"
      ],
      "metadata": {
        "id": "EKQLjW8iMQkA"
      },
      "id": "EKQLjW8iMQkA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1226132b-2c5f-4073-bfdb-0e36c681c12f",
      "metadata": {
        "id": "1226132b-2c5f-4073-bfdb-0e36c681c12f"
      },
      "outputs": [],
      "source": [
        "documents = SimpleDirectoryReader(\"./data\").load_data()\n",
        "index = VectorStoreIndex.from_documents(documents=documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c9b3567-c95c-473d-afc0-516b5f35e197",
      "metadata": {
        "id": "8c9b3567-c95c-473d-afc0-516b5f35e197"
      },
      "outputs": [],
      "source": [
        "tools = [\n",
        "    Tool(\n",
        "        name=\"LlamaIndex\",\n",
        "        func=lambda q: str(index.as_query_engine().query(q)),\n",
        "        description=\"useful for when you want to answer questions about the author. The input to this tool should be a complete english sentence.\",\n",
        "        return_direct=True,\n",
        "    ),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "374e9f69-1f75-4a62-afdc-22f748d4bddd",
      "metadata": {
        "id": "374e9f69-1f75-4a62-afdc-22f748d4bddd"
      },
      "outputs": [],
      "source": [
        "# set Logging to DEBUG for more detailed outputs\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
        "llm = ChatOpenAI(temperature=0)\n",
        "agent_executor = initialize_agent(\n",
        "    tools, llm, agent=\"conversational-react-description\", memory=memory\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "579fbc9f-9f13-416c-bde4-7e56fb899727",
      "metadata": {
        "id": "579fbc9f-9f13-416c-bde4-7e56fb899727"
      },
      "outputs": [],
      "source": [
        "agent_executor.run(input=\"hi, i am bob\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9841c8e-f90b-4e40-a2f9-ad1e98bb9eef",
      "metadata": {
        "id": "a9841c8e-f90b-4e40-a2f9-ad1e98bb9eef"
      },
      "outputs": [],
      "source": [
        "agent_executor.run(input=\"what's my name?\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent_executor.run(input=\"who is the author of this document?\")"
      ],
      "metadata": {
        "id": "iIs9z-3Z5Ehc"
      },
      "id": "iIs9z-3Z5Ehc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent_executor.run(input=\"please summarize the document\")"
      ],
      "metadata": {
        "id": "fB65FBdm5QSv"
      },
      "id": "fB65FBdm5QSv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent_executor.run(input=\"please summarize the document in Korean\")"
      ],
      "metadata": {
        "id": "VxFh16gc5bW7"
      },
      "id": "VxFh16gc5bW7",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}