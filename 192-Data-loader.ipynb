{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMxRfEFmkzFpRdPYAJEvbKm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JSJeong-me/GPT-Web/blob/main/192-Data-loader.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama-index"
      ],
      "metadata": {
        "id": "dWsNyQv1MukU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://docs.llamaindex.ai/en/stable/getting_started/starter_example.html"
      ],
      "metadata": {
        "id": "Gq0P5IxdMKuc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# from llama_index import VectorStoreIndex, SimpleWebPageReader\n",
        "# Enter your OpenAI key below:\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"sk-\""
      ],
      "metadata": {
        "id": "0DUEhmN_M7ts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir data"
      ],
      "metadata": {
        "id": "clhGCqC3NGsr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fvrviUSRMKDf"
      },
      "outputs": [],
      "source": [
        "from llama_index import VectorStoreIndex, SimpleDirectoryReader\n",
        "\n",
        "documents = SimpleDirectoryReader(\"data\").load_data()\n",
        "index = VectorStoreIndex.from_documents(documents)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query_engine = index.as_query_engine()\n",
        "response = query_engine.query(\"What did the author do growing up?\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "TSngt0-XNEO9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "로깅을 사용하여 쿼리 및 이벤트 보기"
      ],
      "metadata": {
        "id": "WS0juZ5CNqqd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import sys\n",
        "\n",
        "logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)\n",
        "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
      ],
      "metadata": {
        "id": "mcS6NjzINpUR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index.storage_context.persist()"
      ],
      "metadata": {
        "id": "WdGKPDxYN4Jm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os.path\n",
        "from llama_index import (\n",
        "    VectorStoreIndex,\n",
        "    SimpleDirectoryReader,\n",
        "    StorageContext,\n",
        "    load_index_from_storage,\n",
        ")\n",
        "\n",
        "# check if storage already exists\n",
        "if not os.path.exists(\"./storage\"):\n",
        "    # load the documents and create the index\n",
        "    documents = SimpleDirectoryReader(\"data\").load_data()\n",
        "    index = VectorStoreIndex.from_documents(documents)\n",
        "    # store it for later\n",
        "    index.storage_context.persist()\n",
        "else:\n",
        "    # load the existing index\n",
        "    storage_context = StorageContext.from_defaults(persist_dir=\"./storage\")\n",
        "    index = load_index_from_storage(storage_context)\n",
        "\n",
        "# either way we can now query the index\n",
        "query_engine = index.as_query_engine()\n",
        "response = query_engine.query(\"What did the author do growing up?\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "zyXEe5EAN6x8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}